{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/vision/polina/projects/wmh/dhollidt/conda/envs/nerfstudio2/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /data/vision/polina/projects/wmh/dhollidt/conda/envs/nerfstudio2/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIlEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from nerfstudio.model_components.nesf_components import *\n",
    "import torch\n",
    "from torch.profiler import profile, record_function, ProfilerActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_size 0.004\n",
      "quant_size 0.001\n",
      "window_size 4\n",
      "patch_size 1\n",
      "patch_size 0.004\n",
      "patch_size 0.004\n",
      "window_sizes [0.016, 0.032, 0.064, 0.128]\n",
      "grid_sizes [0.004, 0.008, 0.016, 0.032]\n",
      "quant_sizes [0.001, 0.002, 0.004, 0.008]\n",
      "8089680\n"
     ]
    }
   ],
   "source": [
    "model = TranformerEncoderModelConfig(\n",
    "    num_layers=8,\n",
    "    num_heads=8,\n",
    "    dim_feed_forward=128,\n",
    "    feature_dim=128,\n",
    "    ).setup(input_size=103)\n",
    "\n",
    "model = StratifiedTransformerWrapperConfig().setup(input_size=103)\n",
    "\n",
    "# model prameters\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "model.to(\"cuda:0\")\n",
    "model.train()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "print(next(model.parameters()).device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.332539081573486</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m5.332539081573486\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current memory usage: 4115.36 MB\n",
      " After clear  - Current memory usage: 4115.36 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.1529700756073</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m5.1529700756073\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current memory usage: 4116.01 MB\n",
      " After clear  - Current memory usage: 4116.01 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.439337730407715</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m5.439337730407715\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current memory usage: 4116.06 MB\n",
      " After clear  - Current memory usage: 4116.06 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.229464292526245</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m5.229464292526245\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current memory usage: 4114.39 MB\n",
      " After clear  - Current memory usage: 4114.39 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.199592113494873</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m5.199592113494873\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current memory usage: 4113.46 MB\n",
      " After clear  - Current memory usage: 4113.46 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.5295281410217285</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m5.5295281410217285\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current memory usage: 4113.12 MB\n",
      " After clear  - Current memory usage: 4113.12 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.329776287078857</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m5.329776287078857\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current memory usage: 4114.76 MB\n",
      " After clear  - Current memory usage: 4114.76 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.297401666641235</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m5.297401666641235\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current memory usage: 4115.49 MB\n",
      " After clear  - Current memory usage: 4115.49 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.195030927658081</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m5.195030927658081\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current memory usage: 4114.41 MB\n",
      " After clear  - Current memory usage: 4114.41 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.332430362701416</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m5.332430362701416\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current memory usage: 4117.58 MB\n",
      " After clear  - Current memory usage: 4117.58 MB\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    input_data = torch.randn(1, 128000, 103, device=\"cuda:0\", requires_grad=True)\n",
    "    points_xyz = torch.randn(1, 128000, 3, device=\"cuda:0\", requires_grad=False)\n",
    "    output_data = torch.randn(1, 128000, 128, device=\"cuda:0\")\n",
    "    out = model(input_data, batch={\"points_xyz\": points_xyz})\n",
    "    print(f\"Current memory usage: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\" After clear  - Current memory usage: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.48016786575317383</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.48016786575317383\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3993723392486572</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.3993723392486572\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3594224452972412</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.3594224452972412\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3305337429046631</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.3305337429046631\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.482318639755249</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.482318639755249\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.321502685546875</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.321502685546875\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current memory usage: 61.95 MB\n",
      "Max memory usage: 229.40 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3587830066680908</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.3587830066680908\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4535503387451172</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.4535503387451172\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3151557445526123</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.3151557445526123\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.39609503746032715</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.39609503746032715\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.38425612449645996</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.38425612449645996\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current memory usage: 62.12 MB\n",
      "Max memory usage: 72.87 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.39000988006591797</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.39000988006591797\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.39855480194091797</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.39855480194091797\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3925809860229492</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.3925809860229492\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4179544448852539</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.4179544448852539\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.30950498580932617</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.30950498580932617\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current memory usage: 62.46 MB\n",
      "Max memory usage: 81.80 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4850142002105713</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.4850142002105713\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.34949803352355957</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.34949803352355957\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.394578218460083</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.394578218460083\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4269425868988037</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.4269425868988037\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3994874954223633</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.3994874954223633\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current memory usage: 63.15 MB\n",
      "Max memory usage: 97.57 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.43028903007507324</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.43028903007507324\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.32970714569091797</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.32970714569091797\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6622068881988525</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.6622068881988525\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3495488166809082</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.3495488166809082\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3393857479095459</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.3393857479095459\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current memory usage: 64.53 MB\n",
      "Max memory usage: 133.77 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3780546188354492</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.3780546188354492\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.38126587867736816</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.38126587867736816\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5051140785217285</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.5051140785217285\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.30080199241638184</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.30080199241638184\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3607463836669922</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.3607463836669922\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current memory usage: 67.29 MB\n",
      "Max memory usage: 204.42 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4180600643157959</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.4180600643157959\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5621168613433838</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.5621168613433838\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3732872009277344</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.3732872009277344\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.36989736557006836</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.36989736557006836\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3526296615600586</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.3526296615600586\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current memory usage: 73.80 MB\n",
      "Max memory usage: 348.99 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8835210800170898</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.8835210800170898\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4397616386413574</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.4397616386413574\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4289538860321045</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.4289538860321045\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5958101749420166</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.5958101749420166\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.49665164947509766</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.49665164947509766\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current memory usage: 83.84 MB\n",
      "Max memory usage: 632.09 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7235066890716553</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.7235066890716553\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9367644786834717</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.9367644786834717\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6797940731048584</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.6797940731048584\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8819441795349121</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.8819441795349121\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7622120380401611</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m0.7622120380401611\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current memory usage: 106.84 MB\n",
      "Max memory usage: 1201.96 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.0666534900665283</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m2.0666534900665283\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.7351932525634766</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m1.7351932525634766\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.703500509262085</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m1.703500509262085\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.7420198917388916</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m1.7420198917388916\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.8956401348114014</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m1.8956401348114014\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current memory usage: 150.02 MB\n",
      "Max memory usage: 2338.01 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.455312490463257</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m5.455312490463257\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.440865516662598</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m5.440865516662598\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.4075026512146</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m5.4075026512146\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.461700677871704</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m5.461700677871704\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StratifiedTransformerWrapper forward time:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.496267795562744</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StratifiedTransformerWrapper forward time:  \u001b[1;36m5.496267795562744\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current memory usage: 239.27 MB\n",
      "Max memory usage: 4614.78 MB\n",
      "[128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65535, 131072]\n",
      "[229.40185546875, 72.8740234375, 81.80126953125, 97.57373046875, 133.76806640625, 204.41650390625, 348.9931640625, 632.0888671875, 1201.96337890625, 2338.0078125, 4614.77587890625]\n",
      "Input memory usage: 51.5 MB\n",
      "Out memory usage: 24.0 MB\n",
      "Loss memory usage: 3.814697265625e-06 MB\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_data = torch.randn(1, 128, 103, device=\"cuda:0\", requires_grad=True)\n",
    "points_xyz = torch.randn(1, 128, 3, device=\"cuda:0\", requires_grad=False)\n",
    "output_data = torch.randn(1, 128, 128, device=\"cuda:0\")\n",
    "out = model(input_data, batch={\"points_xyz\": points_xyz})\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "B = 1\n",
    "S = 128\n",
    "\n",
    "BS = [128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65535, 131072]\n",
    "mems = []\n",
    "for S in  BS:\n",
    "    for i in range(5):\n",
    "        input_data = torch.randn(B, S, 103, device=\"cuda:0\", requires_grad=True)\n",
    "        points_xyz = torch.rand(B, S, 3, device=\"cuda:0\", requires_grad=False)\n",
    "        output_data = torch.randn(B, S, 48, device=\"cuda:0\")\n",
    "        out = model(input_data, batch={\"points_xyz\": points_xyz})\n",
    "        loss = torch.nn.functional.mse_loss(output_data, out)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Current memory usage: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
    "    print(f\"Max memory usage: {torch.cuda.max_memory_allocated() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    mems.append(torch.cuda.max_memory_allocated() / 1024**2)\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    \n",
    "    \n",
    "print(BS)\n",
    "print(mems)\n",
    "\n",
    "# plot BS agains mems\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.plot(BS, mems)\n",
    "\n",
    "# memory usage of out loss and input_data\n",
    "print(\"Input memory usage:\", input_data.element_size() * input_data.nelement() / 1024**2, \"MB\")\n",
    "print(\"Out memory usage:\", out.element_size() * out.nelement() / 1024**2, \"MB\")\n",
    "print(\"Loss memory usage:\", loss.element_size() * loss.nelement() / 1024**2, \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m input_data \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39m1\u001b[39m, \u001b[39m128\u001b[39m, \u001b[39m103\u001b[39m, device\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcuda:0\u001b[39m\u001b[39m\"\u001b[39m, requires_grad\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m output_data \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39m1\u001b[39m, \u001b[39m128\u001b[39m, \u001b[39m128\u001b[39m, device\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcuda:0\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m out \u001b[39m=\u001b[39m model(input_data, batch\u001b[39m=\u001b[39m{})\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "input_data = torch.randn(1, 128, 103, device=\"cuda:0\", requires_grad=True)\n",
    "output_data = torch.randn(1, 128, 128, device=\"cuda:0\")\n",
    "out = model(input_data, batch={})\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "B = 2\n",
    "S = 128\n",
    "\n",
    "BS = [1,2,3,4,6, 8, 10]\n",
    "mems = []\n",
    "for B in  BS:\n",
    "    with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "            profile_memory=True, record_shapes=True, with_stack=False) as prof:\n",
    "        for i in range(5):\n",
    "            input_data = torch.randn(B, S, 103, device=\"cuda:0\", requires_grad=True)\n",
    "            output_data = torch.randn(B, S, 128, device=\"cuda:0\")\n",
    "            out = model(input_data, batch={})\n",
    "            loss = torch.nn.functional.mse_loss(output_data, out)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    print(f\"Current memory usage: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
    "    print(f\"Max memory usage: {torch.cuda.max_memory_allocated() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    mems.append(torch.cuda.max_memory_allocated() / 1024**2)\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    \n",
    "    \n",
    "print(BS)\n",
    "print(mems)\n",
    "\n",
    "# plot BS agains mems\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.plot(BS, mems)\n",
    "\n",
    "# memory usage of out loss and input_data\n",
    "print(\"Input memory usage:\", input_data.element_size() * input_data.nelement() / 1024**2, \"MB\")\n",
    "print(\"Out memory usage:\", out.element_size() * out.nelement() / 1024**2, \"MB\")\n",
    "print(\"Loss memory usage:\", loss.element_size() * loss.nelement() / 1024**2, \"MB\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B = 1, S = 2048\n",
    "Max memory usage: 2618.83 MB\n",
    "\n",
    "## B = 1, S = 2048\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 128])\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                            aten::empty         0.84%      17.213ms         0.91%      18.798ms       8.743us       0.000us         0.00%       7.000us       0.003us       2.62 Kb       2.62 Kb     437.69 Mb     437.69 Mb          2150  \n",
      "                                               [memory]         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us         640 b         640 b    -107.85 Mb    -107.85 Mb          1029  \n",
      "                                            aten::randn         0.01%     235.000us         0.13%       2.676ms     133.800us       0.000us         0.00%      73.000us       3.650us           0 b           0 b       1.13 Mb           0 b            20  \n",
      "                                          aten::normal_         0.02%     416.000us         0.04%     732.000us      36.600us      60.000us         0.10%      73.000us       3.650us           0 b           0 b           0 b           0 b            20  \n",
      "                                  cudaStreamIsCapturing         0.03%     612.000us         0.03%     612.000us       1.764us     134.000us         0.22%     134.000us       0.386us           0 b           0 b           0 b           0 b           347  \n",
      "                                       cudaLaunchKernel         7.35%     151.039ms         7.35%     151.039ms       9.351us       4.610ms         7.69%       4.610ms       0.285us           0 b           0 b           0 b           0 b         16152  \n",
      "void at::native::(anonymous namespace)::distribution...         0.00%       0.000us         0.00%       0.000us       0.000us      60.000us         0.10%      60.000us       3.000us           0 b           0 b           0 b           0 b            20  \n",
      "                                           aten::linear         0.20%       4.168ms        21.97%     451.660ms       1.369ms       0.000us         0.00%       2.666ms       8.079us           0 b           0 b      30.62 Mb           0 b           330  \n",
      "                                                aten::t         5.57%     114.433ms         5.97%     122.682ms      74.353us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1650  \n",
      "                                        aten::transpose         9.72%     199.731ms         9.92%     203.945ms      66.002us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          3090  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.056s\n",
      "Self CUDA time total: 59.918ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(out.shape)\n",
    "print(prof.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                             aten::view        16.85%     346.283ms        16.85%     346.283ms     223.408us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1550  \n",
      "                                        aten::transpose        10.48%     215.488ms        10.71%     220.029ms      71.207us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          3090  \n",
      "                                       cudaLaunchKernel         7.18%     147.602ms         7.18%     147.602ms       9.083us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b         16250  \n",
      "                                            aten::addmm         6.87%     141.099ms         7.59%     155.956ms     472.594us       2.405ms         4.00%       2.405ms       7.288us           0 b           0 b      30.62 Mb    -299.38 Mb           330  \n",
      "                                                aten::t         5.62%     115.538ms         6.02%     123.753ms      75.002us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1650  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.055s\n",
      "Self CUDA time total: 60.190ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages(group_by_stack_n=5).table(sort_by='self_cpu_time_total', row_limit=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'summary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m summary(transformer, input_size\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m3000\u001b[39m, \u001b[39m48\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'summary' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "summary(transformer, input_size=(1, 3000, 48))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13698990080, 16900292608)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.mem_get_info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_stats = torch.cuda.memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 1            |        cudaMalloc retries: 1         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |    4117 MB |   10117 MB |  149032 MB |  144914 MB |\n",
      "|       from large pool |    4043 MB |   10043 MB |  144985 MB |  140942 MB |\n",
      "|       from small pool |      73 MB |     130 MB |    4046 MB |    3972 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |    4117 MB |   10117 MB |  149032 MB |  144914 MB |\n",
      "|       from large pool |    4043 MB |   10043 MB |  144985 MB |  140942 MB |\n",
      "|       from small pool |      73 MB |     130 MB |    4046 MB |    3972 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |    8144 MB |   14144 MB |   58818 MB |   50674 MB |\n",
      "|       from large pool |    8012 MB |   14012 MB |   58482 MB |   50470 MB |\n",
      "|       from small pool |     132 MB |     138 MB |     336 MB |     204 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |    4026 MB |    4031 MB |   99018 MB |   94991 MB |\n",
      "|       from large pool |    3968 MB |    3972 MB |   94824 MB |   90855 MB |\n",
      "|       from small pool |      58 MB |      60 MB |    4194 MB |    4135 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     659    |    1108    |   39221    |   38562    |\n",
      "|       from large pool |     170    |     339    |    5165    |    4995    |\n",
      "|       from small pool |     489    |    1090    |   34056    |   33567    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     659    |    1108    |   39221    |   38562    |\n",
      "|       from large pool |     170    |     339    |    5165    |    4995    |\n",
      "|       from small pool |     489    |    1090    |   34056    |   33567    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |      77    |      85    |     236    |     159    |\n",
      "|       from large pool |      11    |      18    |      68    |      57    |\n",
      "|       from small pool |      66    |      69    |     168    |     102    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |     230    |     233    |   18334    |   18104    |\n",
      "|       from large pool |      67    |      69    |    2344    |    2277    |\n",
      "|       from small pool |     163    |     172    |   15990    |   15827    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor of shape torch.Size([15, 3]) - 0.00 MB\n",
      "Tensor of shape torch.Size([15, 103, 48]) - 0.28 MB\n",
      "Tensor of shape torch.Size([48]) - 0.00 MB\n",
      "Tensor of shape torch.Size([48]) - 0.00 MB\n",
      "Tensor of shape torch.Size([384]) - 0.00 MB\n",
      "Tensor of shape torch.Size([384]) - 0.00 MB\n",
      "Tensor of shape torch.Size([64, 24, 16, 3]) - 0.28 MB\n",
      "Tensor of shape torch.Size([64, 24, 16, 3]) - 0.28 MB\n",
      "Tensor of shape torch.Size([64, 24, 16, 3]) - 0.28 MB\n",
      "Tensor of shape torch.Size([384]) - 0.00 MB\n",
      "Tensor of shape torch.Size([384]) - 0.00 MB\n",
      "Tensor of shape torch.Size([384]) - 0.00 MB\n",
      "Tensor of shape torch.Size([384]) - 0.00 MB\n",
      "Tensor of shape torch.Size([64, 24, 16, 3]) - 0.28 MB\n",
      "Tensor of shape torch.Size([64, 24, 16, 3]) - 0.28 MB\n",
      "Tensor of shape torch.Size([64, 24, 16, 3]) - 0.28 MB\n",
      "Tensor of shape torch.Size([384]) - 0.00 MB\n",
      "Tensor of shape torch.Size([384]) - 0.00 MB\n",
      "Tensor of shape torch.Size([1152, 384]) - 1.69 MB\n",
      "Tensor of shape torch.Size([1152]) - 0.00 MB\n",
      "Tensor of shape torch.Size([384, 384]) - 0.56 MB\n",
      "Tensor of shape torch.Size([384]) - 0.00 MB\n",
      "Tensor of shape torch.Size([1536, 384]) - 2.25 MB\n",
      "Tensor of shape torch.Size([1536]) - 0.01 MB\n",
      "Tensor of shape torch.Size([384, 1536]) - 2.25 MB\n",
      "Tensor of shape torch.Size([384]) - 0.00 MB\n",
      "Tensor of shape torch.Size([1152, 384]) - 1.69 MB\n",
      "Tensor of shape torch.Size([1152]) - 0.00 MB\n",
      "Tensor of shape torch.Size([384, 384]) - 0.56 MB\n",
      "Tensor of shape torch.Size([384]) - 0.00 MB\n",
      "Tensor of shape torch.Size([1536, 384]) - 2.25 MB\n",
      "Tensor of shape torch.Size([1536]) - 0.01 MB\n",
      "Tensor of shape torch.Size([384, 1536]) - 2.25 MB\n",
      "Tensor of shape torch.Size([384]) - 0.00 MB\n",
      "Tensor of shape torch.Size([96]) - 0.00 MB\n",
      "Tensor of shape torch.Size([96]) - 0.00 MB\n",
      "Tensor of shape torch.Size([96, 96]) - 0.04 MB\n",
      "Tensor of shape torch.Size([96]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([96, 192]) - 0.07 MB\n",
      "Tensor of shape torch.Size([96]) - 0.00 MB\n",
      "Tensor of shape torch.Size([48]) - 0.00 MB\n",
      "Tensor of shape torch.Size([48]) - 0.00 MB\n",
      "Tensor of shape torch.Size([48, 48]) - 0.01 MB\n",
      "Tensor of shape torch.Size([48]) - 0.00 MB\n",
      "Tensor of shape torch.Size([96]) - 0.00 MB\n",
      "Tensor of shape torch.Size([96]) - 0.00 MB\n",
      "Tensor of shape torch.Size([48, 96]) - 0.02 MB\n",
      "Tensor of shape torch.Size([48]) - 0.00 MB\n",
      "Tensor of shape torch.Size([48]) - 0.00 MB\n",
      "Tensor of shape torch.Size([48]) - 0.00 MB\n",
      "Tensor of shape torch.Size([]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192, 384]) - 0.28 MB\n",
      "Tensor of shape torch.Size([384]) - 0.00 MB\n",
      "Tensor of shape torch.Size([384]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192, 192]) - 0.14 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192, 768]) - 0.56 MB\n",
      "Tensor of shape torch.Size([768]) - 0.00 MB\n",
      "Tensor of shape torch.Size([768, 192]) - 0.56 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192, 192]) - 0.14 MB\n",
      "Tensor of shape torch.Size([576]) - 0.00 MB\n",
      "Tensor of shape torch.Size([576, 192]) - 0.42 MB\n",
      "Tensor of shape torch.Size([64, 12, 16, 3]) - 0.14 MB\n",
      "Tensor of shape torch.Size([64, 12, 16, 3]) - 0.14 MB\n",
      "Tensor of shape torch.Size([64, 12, 16, 3]) - 0.14 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192, 768]) - 0.56 MB\n",
      "Tensor of shape torch.Size([768]) - 0.00 MB\n",
      "Tensor of shape torch.Size([768, 192]) - 0.56 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192, 192]) - 0.14 MB\n",
      "Tensor of shape torch.Size([576]) - 0.00 MB\n",
      "Tensor of shape torch.Size([576, 192]) - 0.42 MB\n",
      "Tensor of shape torch.Size([64, 12, 16, 3]) - 0.14 MB\n",
      "Tensor of shape torch.Size([64, 12, 16, 3]) - 0.14 MB\n",
      "Tensor of shape torch.Size([64, 12, 16, 3]) - 0.14 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192, 768]) - 0.56 MB\n",
      "Tensor of shape torch.Size([768]) - 0.00 MB\n",
      "Tensor of shape torch.Size([768, 192]) - 0.56 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192, 192]) - 0.14 MB\n",
      "Tensor of shape torch.Size([576]) - 0.00 MB\n",
      "Tensor of shape torch.Size([576, 192]) - 0.42 MB\n",
      "Tensor of shape torch.Size([64, 12, 16, 3]) - 0.14 MB\n",
      "Tensor of shape torch.Size([64, 12, 16, 3]) - 0.14 MB\n",
      "Tensor of shape torch.Size([64, 12, 16, 3]) - 0.14 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192, 768]) - 0.56 MB\n",
      "Tensor of shape torch.Size([768]) - 0.00 MB\n",
      "Tensor of shape torch.Size([768, 192]) - 0.56 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192, 192]) - 0.14 MB\n",
      "Tensor of shape torch.Size([576]) - 0.00 MB\n",
      "Tensor of shape torch.Size([576, 192]) - 0.42 MB\n",
      "Tensor of shape torch.Size([64, 12, 16, 3]) - 0.14 MB\n",
      "Tensor of shape torch.Size([64, 12, 16, 3]) - 0.14 MB\n",
      "Tensor of shape torch.Size([64, 12, 16, 3]) - 0.14 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([15, 103, 48]) - 0.28 MB\n",
      "Tensor of shape torch.Size([48]) - 0.00 MB\n",
      "Tensor of shape torch.Size([48]) - 0.00 MB\n",
      "Tensor of shape torch.Size([48]) - 0.00 MB\n",
      "Tensor of shape torch.Size([48]) - 0.00 MB\n",
      "Tensor of shape torch.Size([64, 3, 16, 3]) - 0.04 MB\n",
      "Tensor of shape torch.Size([64, 3, 16, 3]) - 0.04 MB\n",
      "Tensor of shape torch.Size([64, 3, 16, 3]) - 0.04 MB\n",
      "Tensor of shape torch.Size([144, 48]) - 0.03 MB\n",
      "Tensor of shape torch.Size([144]) - 0.00 MB\n",
      "Tensor of shape torch.Size([48, 48]) - 0.01 MB\n",
      "Tensor of shape torch.Size([48]) - 0.00 MB\n",
      "Tensor of shape torch.Size([48]) - 0.00 MB\n",
      "Tensor of shape torch.Size([48]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192, 48]) - 0.04 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([48, 192]) - 0.04 MB\n",
      "Tensor of shape torch.Size([48]) - 0.00 MB\n",
      "Tensor of shape torch.Size([48]) - 0.00 MB\n",
      "Tensor of shape torch.Size([48]) - 0.00 MB\n",
      "Tensor of shape torch.Size([64, 3, 16, 3]) - 0.04 MB\n",
      "Tensor of shape torch.Size([64, 3, 16, 3]) - 0.04 MB\n",
      "Tensor of shape torch.Size([64, 3, 16, 3]) - 0.04 MB\n",
      "Tensor of shape torch.Size([144, 48]) - 0.03 MB\n",
      "Tensor of shape torch.Size([144]) - 0.00 MB\n",
      "Tensor of shape torch.Size([48, 48]) - 0.01 MB\n",
      "Tensor of shape torch.Size([48]) - 0.00 MB\n",
      "Tensor of shape torch.Size([48]) - 0.00 MB\n",
      "Tensor of shape torch.Size([48]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192, 48]) - 0.04 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([48, 192]) - 0.04 MB\n",
      "Tensor of shape torch.Size([48]) - 0.00 MB\n",
      "Tensor of shape torch.Size([48]) - 0.00 MB\n",
      "Tensor of shape torch.Size([48]) - 0.00 MB\n",
      "Tensor of shape torch.Size([96, 48]) - 0.02 MB\n",
      "Tensor of shape torch.Size([96]) - 0.00 MB\n",
      "Tensor of shape torch.Size([96]) - 0.00 MB\n",
      "Tensor of shape torch.Size([64, 6, 16, 3]) - 0.07 MB\n",
      "Tensor of shape torch.Size([64, 6, 16, 3]) - 0.07 MB\n",
      "Tensor of shape torch.Size([64, 6, 16, 3]) - 0.07 MB\n",
      "Tensor of shape torch.Size([288, 96]) - 0.11 MB\n",
      "Tensor of shape torch.Size([288]) - 0.00 MB\n",
      "Tensor of shape torch.Size([96, 96]) - 0.04 MB\n",
      "Tensor of shape torch.Size([96]) - 0.00 MB\n",
      "Tensor of shape torch.Size([96]) - 0.00 MB\n",
      "Tensor of shape torch.Size([96]) - 0.00 MB\n",
      "Tensor of shape torch.Size([384, 96]) - 0.14 MB\n",
      "Tensor of shape torch.Size([384]) - 0.00 MB\n",
      "Tensor of shape torch.Size([96, 384]) - 0.14 MB\n",
      "Tensor of shape torch.Size([96]) - 0.00 MB\n",
      "Tensor of shape torch.Size([96]) - 0.00 MB\n",
      "Tensor of shape torch.Size([96]) - 0.00 MB\n",
      "Tensor of shape torch.Size([64, 6, 16, 3]) - 0.07 MB\n",
      "Tensor of shape torch.Size([64, 6, 16, 3]) - 0.07 MB\n",
      "Tensor of shape torch.Size([64, 6, 16, 3]) - 0.07 MB\n",
      "Tensor of shape torch.Size([288, 96]) - 0.11 MB\n",
      "Tensor of shape torch.Size([288]) - 0.00 MB\n",
      "Tensor of shape torch.Size([96, 96]) - 0.04 MB\n",
      "Tensor of shape torch.Size([96]) - 0.00 MB\n",
      "Tensor of shape torch.Size([96]) - 0.00 MB\n",
      "Tensor of shape torch.Size([96]) - 0.00 MB\n",
      "Tensor of shape torch.Size([384, 96]) - 0.14 MB\n",
      "Tensor of shape torch.Size([384]) - 0.00 MB\n",
      "Tensor of shape torch.Size([96, 384]) - 0.14 MB\n",
      "Tensor of shape torch.Size([96]) - 0.00 MB\n",
      "Tensor of shape torch.Size([96]) - 0.00 MB\n",
      "Tensor of shape torch.Size([96]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192, 96]) - 0.07 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([64, 12, 16, 3]) - 0.14 MB\n",
      "Tensor of shape torch.Size([64, 12, 16, 3]) - 0.14 MB\n",
      "Tensor of shape torch.Size([64, 12, 16, 3]) - 0.14 MB\n",
      "Tensor of shape torch.Size([576, 192]) - 0.42 MB\n",
      "Tensor of shape torch.Size([576]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192, 192]) - 0.14 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([768, 192]) - 0.56 MB\n",
      "Tensor of shape torch.Size([768]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192, 768]) - 0.56 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([64, 12, 16, 3]) - 0.14 MB\n",
      "Tensor of shape torch.Size([64, 12, 16, 3]) - 0.14 MB\n",
      "Tensor of shape torch.Size([64, 12, 16, 3]) - 0.14 MB\n",
      "Tensor of shape torch.Size([576, 192]) - 0.42 MB\n",
      "Tensor of shape torch.Size([576]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192, 192]) - 0.14 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([768, 192]) - 0.56 MB\n",
      "Tensor of shape torch.Size([768]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192, 768]) - 0.56 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([64, 12, 16, 3]) - 0.14 MB\n",
      "Tensor of shape torch.Size([64, 12, 16, 3]) - 0.14 MB\n",
      "Tensor of shape torch.Size([64, 12, 16, 3]) - 0.14 MB\n",
      "Tensor of shape torch.Size([576, 192]) - 0.42 MB\n",
      "Tensor of shape torch.Size([576]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192, 192]) - 0.14 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([768, 192]) - 0.56 MB\n",
      "Tensor of shape torch.Size([768]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192, 768]) - 0.56 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([64, 12, 16, 3]) - 0.14 MB\n",
      "Tensor of shape torch.Size([64, 12, 16, 3]) - 0.14 MB\n",
      "Tensor of shape torch.Size([64, 12, 16, 3]) - 0.14 MB\n",
      "Tensor of shape torch.Size([576, 192]) - 0.42 MB\n",
      "Tensor of shape torch.Size([576]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192, 192]) - 0.14 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([768, 192]) - 0.56 MB\n",
      "Tensor of shape torch.Size([768]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192, 768]) - 0.56 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([64, 12, 16, 3]) - 0.14 MB\n",
      "Tensor of shape torch.Size([64, 12, 16, 3]) - 0.14 MB\n",
      "Tensor of shape torch.Size([64, 12, 16, 3]) - 0.14 MB\n",
      "Tensor of shape torch.Size([576, 192]) - 0.42 MB\n",
      "Tensor of shape torch.Size([576]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192, 192]) - 0.14 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([768, 192]) - 0.56 MB\n",
      "Tensor of shape torch.Size([768]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192, 768]) - 0.56 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([64, 12, 16, 3]) - 0.14 MB\n",
      "Tensor of shape torch.Size([64, 12, 16, 3]) - 0.14 MB\n",
      "Tensor of shape torch.Size([64, 12, 16, 3]) - 0.14 MB\n",
      "Tensor of shape torch.Size([576, 192]) - 0.42 MB\n",
      "Tensor of shape torch.Size([576]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192, 192]) - 0.14 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([768, 192]) - 0.56 MB\n",
      "Tensor of shape torch.Size([768]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192, 768]) - 0.56 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([384, 192]) - 0.28 MB\n",
      "Tensor of shape torch.Size([384]) - 0.00 MB\n",
      "Tensor of shape torch.Size([384]) - 0.00 MB\n",
      "Tensor of shape torch.Size([64, 24, 16, 3]) - 0.28 MB\n",
      "Tensor of shape torch.Size([64, 24, 16, 3]) - 0.28 MB\n",
      "Tensor of shape torch.Size([64, 24, 16, 3]) - 0.28 MB\n",
      "Tensor of shape torch.Size([1152, 384]) - 1.69 MB\n",
      "Tensor of shape torch.Size([1152]) - 0.00 MB\n",
      "Tensor of shape torch.Size([384, 384]) - 0.56 MB\n",
      "Tensor of shape torch.Size([384]) - 0.00 MB\n",
      "Tensor of shape torch.Size([384]) - 0.00 MB\n",
      "Tensor of shape torch.Size([384]) - 0.00 MB\n",
      "Tensor of shape torch.Size([1536, 384]) - 2.25 MB\n",
      "Tensor of shape torch.Size([1536]) - 0.01 MB\n",
      "Tensor of shape torch.Size([384, 1536]) - 2.25 MB\n",
      "Tensor of shape torch.Size([384]) - 0.00 MB\n",
      "Tensor of shape torch.Size([384]) - 0.00 MB\n",
      "Tensor of shape torch.Size([384]) - 0.00 MB\n",
      "Tensor of shape torch.Size([64, 24, 16, 3]) - 0.28 MB\n",
      "Tensor of shape torch.Size([64, 24, 16, 3]) - 0.28 MB\n",
      "Tensor of shape torch.Size([64, 24, 16, 3]) - 0.28 MB\n",
      "Tensor of shape torch.Size([1152, 384]) - 1.69 MB\n",
      "Tensor of shape torch.Size([1152]) - 0.00 MB\n",
      "Tensor of shape torch.Size([384, 384]) - 0.56 MB\n",
      "Tensor of shape torch.Size([384]) - 0.00 MB\n",
      "Tensor of shape torch.Size([384]) - 0.00 MB\n",
      "Tensor of shape torch.Size([384]) - 0.00 MB\n",
      "Tensor of shape torch.Size([1536, 384]) - 2.25 MB\n",
      "Tensor of shape torch.Size([1536]) - 0.01 MB\n",
      "Tensor of shape torch.Size([384, 1536]) - 2.25 MB\n",
      "Tensor of shape torch.Size([384]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192, 192]) - 0.14 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([384]) - 0.00 MB\n",
      "Tensor of shape torch.Size([384]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192, 384]) - 0.28 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([96]) - 0.00 MB\n",
      "Tensor of shape torch.Size([96]) - 0.00 MB\n",
      "Tensor of shape torch.Size([96, 96]) - 0.04 MB\n",
      "Tensor of shape torch.Size([96]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([96, 192]) - 0.07 MB\n",
      "Tensor of shape torch.Size([96]) - 0.00 MB\n",
      "Tensor of shape torch.Size([48]) - 0.00 MB\n",
      "Tensor of shape torch.Size([48]) - 0.00 MB\n",
      "Tensor of shape torch.Size([48, 48]) - 0.01 MB\n",
      "Tensor of shape torch.Size([48]) - 0.00 MB\n",
      "Tensor of shape torch.Size([96]) - 0.00 MB\n",
      "Tensor of shape torch.Size([96]) - 0.00 MB\n",
      "Tensor of shape torch.Size([48, 96]) - 0.02 MB\n",
      "Tensor of shape torch.Size([48]) - 0.00 MB\n",
      "Tensor of shape torch.Size([1, 131072, 103]) - 51.50 MB\n",
      "Tensor of shape torch.Size([1, 131072, 3]) - 1.50 MB\n",
      "Tensor of shape torch.Size([1, 131072, 48]) - 24.00 MB\n",
      "Tensor of shape torch.Size([]) - 0.00 MB\n",
      "Tensor of shape torch.Size([]) - 0.00 MB\n",
      "Tensor of shape torch.Size([]) - 0.00 MB\n",
      "Tensor of shape torch.Size([]) - 0.00 MB\n",
      "Tensor of shape torch.Size([]) - 0.00 MB\n",
      "Tensor of shape torch.Size([]) - 0.00 MB\n",
      "Tensor of shape torch.Size([]) - 0.00 MB\n",
      "Tensor of shape torch.Size([]) - 0.00 MB\n",
      "Tensor of shape torch.Size([]) - 0.00 MB\n",
      "Tensor of shape torch.Size([]) - 0.00 MB\n",
      "Tensor of shape torch.Size([131072, 48]) - 24.00 MB\n",
      "Tensor of shape torch.Size([1, 131072, 48]) - 24.00 MB\n",
      "Tensor of shape torch.Size([]) - 0.00 MB\n",
      "Tensor of shape torch.Size([]) - 0.00 MB\n",
      "Tensor of shape torch.Size([]) - 0.00 MB\n",
      "Tensor of shape torch.Size([48]) - 0.00 MB\n",
      "Tensor of shape torch.Size([48]) - 0.00 MB\n",
      "Tensor of shape torch.Size([64, 3, 16, 3]) - 0.04 MB\n",
      "Tensor of shape torch.Size([64, 3, 16, 3]) - 0.04 MB\n",
      "Tensor of shape torch.Size([64, 3, 16, 3]) - 0.04 MB\n",
      "Tensor of shape torch.Size([144, 48]) - 0.03 MB\n",
      "Tensor of shape torch.Size([144]) - 0.00 MB\n",
      "Tensor of shape torch.Size([48, 48]) - 0.01 MB\n",
      "Tensor of shape torch.Size([48]) - 0.00 MB\n",
      "Tensor of shape torch.Size([48]) - 0.00 MB\n",
      "Tensor of shape torch.Size([48]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192, 48]) - 0.04 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([48, 192]) - 0.04 MB\n",
      "Tensor of shape torch.Size([48]) - 0.00 MB\n",
      "Tensor of shape torch.Size([48]) - 0.00 MB\n",
      "Tensor of shape torch.Size([48]) - 0.00 MB\n",
      "Tensor of shape torch.Size([64, 3, 16, 3]) - 0.04 MB\n",
      "Tensor of shape torch.Size([64, 3, 16, 3]) - 0.04 MB\n",
      "Tensor of shape torch.Size([64, 3, 16, 3]) - 0.04 MB\n",
      "Tensor of shape torch.Size([144, 48]) - 0.03 MB\n",
      "Tensor of shape torch.Size([144]) - 0.00 MB\n",
      "Tensor of shape torch.Size([48, 48]) - 0.01 MB\n",
      "Tensor of shape torch.Size([48]) - 0.00 MB\n",
      "Tensor of shape torch.Size([48]) - 0.00 MB\n",
      "Tensor of shape torch.Size([48]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192, 48]) - 0.04 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([48, 192]) - 0.04 MB\n",
      "Tensor of shape torch.Size([48]) - 0.00 MB\n",
      "Tensor of shape torch.Size([48]) - 0.00 MB\n",
      "Tensor of shape torch.Size([48]) - 0.00 MB\n",
      "Tensor of shape torch.Size([96, 48]) - 0.02 MB\n",
      "Tensor of shape torch.Size([96]) - 0.00 MB\n",
      "Tensor of shape torch.Size([96]) - 0.00 MB\n",
      "Tensor of shape torch.Size([64, 6, 16, 3]) - 0.07 MB\n",
      "Tensor of shape torch.Size([64, 6, 16, 3]) - 0.07 MB\n",
      "Tensor of shape torch.Size([64, 6, 16, 3]) - 0.07 MB\n",
      "Tensor of shape torch.Size([288, 96]) - 0.11 MB\n",
      "Tensor of shape torch.Size([288]) - 0.00 MB\n",
      "Tensor of shape torch.Size([96, 96]) - 0.04 MB\n",
      "Tensor of shape torch.Size([96]) - 0.00 MB\n",
      "Tensor of shape torch.Size([96]) - 0.00 MB\n",
      "Tensor of shape torch.Size([96]) - 0.00 MB\n",
      "Tensor of shape torch.Size([384, 96]) - 0.14 MB\n",
      "Tensor of shape torch.Size([384]) - 0.00 MB\n",
      "Tensor of shape torch.Size([96, 384]) - 0.14 MB\n",
      "Tensor of shape torch.Size([96]) - 0.00 MB\n",
      "Tensor of shape torch.Size([96]) - 0.00 MB\n",
      "Tensor of shape torch.Size([96]) - 0.00 MB\n",
      "Tensor of shape torch.Size([64, 6, 16, 3]) - 0.07 MB\n",
      "Tensor of shape torch.Size([64, 6, 16, 3]) - 0.07 MB\n",
      "Tensor of shape torch.Size([64, 6, 16, 3]) - 0.07 MB\n",
      "Tensor of shape torch.Size([288, 96]) - 0.11 MB\n",
      "Tensor of shape torch.Size([288]) - 0.00 MB\n",
      "Tensor of shape torch.Size([96, 96]) - 0.04 MB\n",
      "Tensor of shape torch.Size([96]) - 0.00 MB\n",
      "Tensor of shape torch.Size([96]) - 0.00 MB\n",
      "Tensor of shape torch.Size([96]) - 0.00 MB\n",
      "Tensor of shape torch.Size([384, 96]) - 0.14 MB\n",
      "Tensor of shape torch.Size([384]) - 0.00 MB\n",
      "Tensor of shape torch.Size([96, 384]) - 0.14 MB\n",
      "Tensor of shape torch.Size([96]) - 0.00 MB\n",
      "Tensor of shape torch.Size([96]) - 0.00 MB\n",
      "Tensor of shape torch.Size([96]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192, 96]) - 0.07 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([64, 12, 16, 3]) - 0.14 MB\n",
      "Tensor of shape torch.Size([64, 12, 16, 3]) - 0.14 MB\n",
      "Tensor of shape torch.Size([64, 12, 16, 3]) - 0.14 MB\n",
      "Tensor of shape torch.Size([576, 192]) - 0.42 MB\n",
      "Tensor of shape torch.Size([576]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192, 192]) - 0.14 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([768, 192]) - 0.56 MB\n",
      "Tensor of shape torch.Size([768]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192, 768]) - 0.56 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([64, 12, 16, 3]) - 0.14 MB\n",
      "Tensor of shape torch.Size([64, 12, 16, 3]) - 0.14 MB\n",
      "Tensor of shape torch.Size([64, 12, 16, 3]) - 0.14 MB\n",
      "Tensor of shape torch.Size([576, 192]) - 0.42 MB\n",
      "Tensor of shape torch.Size([576]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192, 192]) - 0.14 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([768, 192]) - 0.56 MB\n",
      "Tensor of shape torch.Size([768]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192, 768]) - 0.56 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([192]) - 0.00 MB\n",
      "Tensor of shape torch.Size([384, 192]) - 0.28 MB\n",
      "total 186.72000122070312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/vision/polina/projects/wmh/dhollidt/conda/envs/nerfstudio2/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:262: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "total = 0\n",
    "for obj in gc.get_objects():\n",
    "    if torch.is_tensor(obj) and obj.is_cuda:\n",
    "        print(f\"Tensor of shape {obj.size()} - {obj.element_size() * obj.nelement() / 1024**2:.2f} MB\")\n",
    "        total += obj.element_size() * obj.nelement() / 1024**2\n",
    "        del obj\n",
    "print(\"total\", total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'device': 0,\n",
       "  'address': 140565677080576,\n",
       "  'total_size': 134217728,\n",
       "  'allocated_size': 80216064,\n",
       "  'active_size': 80216064,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'large',\n",
       "  'blocks': [{'size': 54001664, 'state': 'active_allocated'},\n",
       "   {'size': 54001664, 'state': 'inactive'},\n",
       "   {'size': 26214400, 'state': 'active_allocated'}]},\n",
       " {'device': 0,\n",
       "  'address': 140567287693312,\n",
       "  'total_size': 2097152,\n",
       "  'allocated_size': 512,\n",
       "  'active_size': 512,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'small',\n",
       "  'blocks': [{'size': 2096128, 'state': 'inactive'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'inactive'}]},\n",
       " {'device': 0,\n",
       "  'address': 140567293984768,\n",
       "  'total_size': 2097152,\n",
       "  'allocated_size': 512,\n",
       "  'active_size': 512,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'small',\n",
       "  'blocks': [{'size': 1771008, 'state': 'inactive'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 325632, 'state': 'inactive'}]},\n",
       " {'device': 0,\n",
       "  'address': 140567325442048,\n",
       "  'total_size': 2097152,\n",
       "  'allocated_size': 2064384,\n",
       "  'active_size': 2064384,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'small',\n",
       "  'blocks': [{'size': 589824, 'state': 'active_allocated'},\n",
       "   {'size': 589824, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 32768, 'state': 'inactive'}]},\n",
       " {'device': 0,\n",
       "  'address': 140567327539200,\n",
       "  'total_size': 2097152,\n",
       "  'allocated_size': 2064384,\n",
       "  'active_size': 2064384,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'small',\n",
       "  'blocks': [{'size': 589824, 'state': 'active_allocated'},\n",
       "   {'size': 589824, 'state': 'active_allocated'},\n",
       "   {'size': 442368, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 32768, 'state': 'inactive'}]},\n",
       " {'device': 0,\n",
       "  'address': 140567329636352,\n",
       "  'total_size': 2097152,\n",
       "  'allocated_size': 2064384,\n",
       "  'active_size': 2064384,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'small',\n",
       "  'blocks': [{'size': 589824, 'state': 'active_allocated'},\n",
       "   {'size': 589824, 'state': 'active_allocated'},\n",
       "   {'size': 442368, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 32768, 'state': 'inactive'}]},\n",
       " {'device': 0,\n",
       "  'address': 140567331733504,\n",
       "  'total_size': 2097152,\n",
       "  'allocated_size': 2064384,\n",
       "  'active_size': 2064384,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'small',\n",
       "  'blocks': [{'size': 589824, 'state': 'active_allocated'},\n",
       "   {'size': 589824, 'state': 'active_allocated'},\n",
       "   {'size': 442368, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 32768, 'state': 'inactive'}]},\n",
       " {'device': 0,\n",
       "  'address': 140569179324416,\n",
       "  'total_size': 2097152,\n",
       "  'allocated_size': 2064384,\n",
       "  'active_size': 2064384,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'small',\n",
       "  'blocks': [{'size': 589824, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 442368, 'state': 'active_allocated'},\n",
       "   {'size': 589824, 'state': 'active_allocated'},\n",
       "   {'size': 32768, 'state': 'inactive'}]},\n",
       " {'device': 0,\n",
       "  'address': 140569181421568,\n",
       "  'total_size': 2097152,\n",
       "  'allocated_size': 215040,\n",
       "  'active_size': 215040,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'small',\n",
       "  'blocks': [{'size': 367616, 'state': 'inactive'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 3584, 'state': 'inactive'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 5632, 'state': 'inactive'},\n",
       "   {'size': 1536, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 206336, 'state': 'inactive'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 36864, 'state': 'active_allocated'},\n",
       "   {'size': 7168, 'state': 'inactive'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 1536, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1536, 'state': 'active_allocated'},\n",
       "   {'size': 2560, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 369152, 'state': 'inactive'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 1536, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 329728, 'state': 'inactive'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 4096, 'state': 'inactive'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 479232, 'state': 'inactive'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 98304, 'state': 'inactive'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'inactive'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'inactive'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 2048, 'state': 'inactive'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'inactive'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 6656, 'state': 'inactive'}]},\n",
       " {'device': 0,\n",
       "  'address': 140569183518720,\n",
       "  'total_size': 2097152,\n",
       "  'allocated_size': 599552,\n",
       "  'active_size': 599552,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'small',\n",
       "  'blocks': [{'size': 791040, 'state': 'inactive'},\n",
       "   {'size': 36864, 'state': 'active_allocated'},\n",
       "   {'size': 64512, 'state': 'inactive'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 23040, 'state': 'inactive'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'inactive'},\n",
       "   {'size': 36864, 'state': 'active_allocated'},\n",
       "   {'size': 23552, 'state': 'inactive'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 36864, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'inactive'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 108544, 'state': 'inactive'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 2560, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'inactive'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 2560, 'state': 'active_allocated'},\n",
       "   {'size': 120320, 'state': 'inactive'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'inactive'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 2560, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 119296, 'state': 'inactive'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 7168, 'state': 'inactive'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 117760, 'state': 'inactive'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 115200, 'state': 'inactive'},\n",
       "   {'size': 1536, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 4096, 'state': 'inactive'}]},\n",
       " {'device': 0,\n",
       "  'address': 140569185615872,\n",
       "  'total_size': 2097152,\n",
       "  'allocated_size': 1707008,\n",
       "  'active_size': 1707008,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'small',\n",
       "  'blocks': [{'size': 104448, 'state': 'inactive'},\n",
       "   {'size': 1536, 'state': 'active_allocated'},\n",
       "   {'size': 73728, 'state': 'active_allocated'},\n",
       "   {'size': 14336, 'state': 'inactive'},\n",
       "   {'size': 9216, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 147968, 'state': 'inactive'},\n",
       "   {'size': 442368, 'state': 'active_allocated'},\n",
       "   {'size': 589824, 'state': 'active_allocated'},\n",
       "   {'size': 589824, 'state': 'active_allocated'},\n",
       "   {'size': 123392, 'state': 'inactive'}]},\n",
       " {'device': 0,\n",
       "  'address': 140569187713024,\n",
       "  'total_size': 918552576,\n",
       "  'allocated_size': 79168000,\n",
       "  'active_size': 79168000,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'large',\n",
       "  'blocks': [{'size': 54002176, 'state': 'active_allocated'},\n",
       "   {'size': 112739840, 'state': 'inactive'},\n",
       "   {'size': 25165824, 'state': 'active_allocated'},\n",
       "   {'size': 726644736, 'state': 'inactive'}]},\n",
       " {'device': 0,\n",
       "  'address': 140571016429568,\n",
       "  'total_size': 2097152,\n",
       "  'allocated_size': 1882112,\n",
       "  'active_size': 1882112,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'small',\n",
       "  'blocks': [{'size': 73728, 'state': 'active_allocated'},\n",
       "   {'size': 442368, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 57344, 'state': 'inactive'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 4096, 'state': 'inactive'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 2048, 'state': 'inactive'},\n",
       "   {'size': 36864, 'state': 'active_allocated'},\n",
       "   {'size': 22016, 'state': 'inactive'},\n",
       "   {'size': 589824, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 442368, 'state': 'active_allocated'},\n",
       "   {'size': 129536, 'state': 'inactive'}]},\n",
       " {'device': 0,\n",
       "  'address': 140571018526720,\n",
       "  'total_size': 2097152,\n",
       "  'allocated_size': 2064384,\n",
       "  'active_size': 2064384,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'small',\n",
       "  'blocks': [{'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 589824, 'state': 'active_allocated'},\n",
       "   {'size': 589824, 'state': 'active_allocated'},\n",
       "   {'size': 294912, 'state': 'active_allocated'},\n",
       "   {'size': 294912, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 32768, 'state': 'inactive'}]},\n",
       " {'device': 0,\n",
       "  'address': 140571020623872,\n",
       "  'total_size': 2097152,\n",
       "  'allocated_size': 2064384,\n",
       "  'active_size': 2064384,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'small',\n",
       "  'blocks': [{'size': 589824, 'state': 'active_allocated'},\n",
       "   {'size': 294912, 'state': 'active_allocated'},\n",
       "   {'size': 294912, 'state': 'active_allocated'},\n",
       "   {'size': 589824, 'state': 'active_allocated'},\n",
       "   {'size': 294912, 'state': 'active_allocated'},\n",
       "   {'size': 32768, 'state': 'inactive'}]},\n",
       " {'device': 0,\n",
       "  'address': 140571022721024,\n",
       "  'total_size': 2097152,\n",
       "  'allocated_size': 2000896,\n",
       "  'active_size': 2000896,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'small',\n",
       "  'blocks': [{'size': 294912, 'state': 'active_allocated'},\n",
       "   {'size': 294912, 'state': 'active_allocated'},\n",
       "   {'size': 294912, 'state': 'active_allocated'},\n",
       "   {'size': 294912, 'state': 'active_allocated'},\n",
       "   {'size': 294912, 'state': 'active_allocated'},\n",
       "   {'size': 294912, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 36864, 'state': 'active_allocated'},\n",
       "   {'size': 5120, 'state': 'inactive'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 3584, 'state': 'inactive'},\n",
       "   {'size': 36864, 'state': 'active_allocated'},\n",
       "   {'size': 48640, 'state': 'inactive'},\n",
       "   {'size': 9216, 'state': 'active_allocated'},\n",
       "   {'size': 38912, 'state': 'inactive'}]},\n",
       " {'device': 0,\n",
       "  'address': 140571951759360,\n",
       "  'total_size': 2097152,\n",
       "  'allocated_size': 512,\n",
       "  'active_size': 512,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'small',\n",
       "  'blocks': [{'size': 1589760, 'state': 'inactive'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 506880, 'state': 'inactive'}]},\n",
       " {'device': 0,\n",
       "  'address': 140571964342272,\n",
       "  'total_size': 1837105152,\n",
       "  'allocated_size': 25165824,\n",
       "  'active_size': 25165824,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'large',\n",
       "  'blocks': [{'size': 315160064, 'state': 'inactive'},\n",
       "   {'size': 25165824, 'state': 'active_allocated'},\n",
       "   {'size': 1496779264, 'state': 'inactive'}]},\n",
       " {'device': 0,\n",
       "  'address': 140576393527296,\n",
       "  'total_size': 20971520,\n",
       "  'allocated_size': 19464192,\n",
       "  'active_size': 19464192,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'large',\n",
       "  'blocks': [{'size': 2359296, 'state': 'active_allocated'},\n",
       "   {'size': 2359296, 'state': 'active_allocated'},\n",
       "   {'size': 1769472, 'state': 'active_allocated'},\n",
       "   {'size': 1769472, 'state': 'active_allocated'},\n",
       "   {'size': 2359296, 'state': 'active_allocated'},\n",
       "   {'size': 2359296, 'state': 'active_allocated'},\n",
       "   {'size': 1769472, 'state': 'active_allocated'},\n",
       "   {'size': 2359296, 'state': 'active_allocated'},\n",
       "   {'size': 2359296, 'state': 'active_allocated'},\n",
       "   {'size': 1507328, 'state': 'inactive'}]},\n",
       " {'device': 0,\n",
       "  'address': 140576414498816,\n",
       "  'total_size': 2097152,\n",
       "  'allocated_size': 2066432,\n",
       "  'active_size': 2066432,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'small',\n",
       "  'blocks': [{'size': 589824, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 442368, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 296960, 'state': 'active_allocated'},\n",
       "   {'size': 30720, 'state': 'inactive'}]},\n",
       " {'device': 0,\n",
       "  'address': 140576424984576,\n",
       "  'total_size': 2097152,\n",
       "  'allocated_size': 1967616,\n",
       "  'active_size': 1967616,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'small',\n",
       "  'blocks': [{'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 296960, 'state': 'active_allocated'},\n",
       "   {'size': 73728, 'state': 'active_allocated'},\n",
       "   {'size': 73728, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 36864, 'state': 'active_allocated'},\n",
       "   {'size': 9216, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 589824, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 129536, 'state': 'inactive'}]},\n",
       " {'device': 0,\n",
       "  'address': 140576429178880,\n",
       "  'total_size': 2097152,\n",
       "  'allocated_size': 1993728,\n",
       "  'active_size': 1993728,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'small',\n",
       "  'blocks': [{'size': 589824, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 36864, 'state': 'active_allocated'},\n",
       "   {'size': 17408, 'state': 'inactive'},\n",
       "   {'size': 73728, 'state': 'active_allocated'},\n",
       "   {'size': 6144, 'state': 'active_allocated'},\n",
       "   {'size': 9216, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 1536, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'inactive'},\n",
       "   {'size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 36864, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'inactive'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 36864, 'state': 'active_allocated'},\n",
       "   {'size': 9216, 'state': 'active_allocated'},\n",
       "   {'size': 4608, 'state': 'active_allocated'},\n",
       "   {'size': 1536, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 2560, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 27136, 'state': 'inactive'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 110592, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 110592, 'state': 'active_allocated'},\n",
       "   {'size': 1536, 'state': 'active_allocated'},\n",
       "   {'size': 1536, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 1536, 'state': 'active_allocated'},\n",
       "   {'size': 1536, 'state': 'active_allocated'},\n",
       "   {'size': 73728, 'state': 'active_allocated'},\n",
       "   {'size': 73728, 'state': 'active_allocated'},\n",
       "   {'size': 36864, 'state': 'active_allocated'},\n",
       "   {'size': 294912, 'state': 'active_allocated'},\n",
       "   {'size': 73728, 'state': 'active_allocated'},\n",
       "   {'size': 22528, 'state': 'inactive'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 2560, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 2560, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 36864, 'state': 'active_allocated'},\n",
       "   {'size': 36864, 'state': 'active_allocated'},\n",
       "   {'size': 35328, 'state': 'inactive'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'}]},\n",
       " {'device': 0,\n",
       "  'address': 140576431276032,\n",
       "  'total_size': 2097152,\n",
       "  'allocated_size': 1998336,\n",
       "  'active_size': 1998336,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'small',\n",
       "  'blocks': [{'size': 27648, 'state': 'active_allocated'},\n",
       "   {'size': 36864, 'state': 'active_allocated'},\n",
       "   {'size': 1536, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 1536, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 1536, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 36864, 'state': 'active_allocated'},\n",
       "   {'size': 29184, 'state': 'inactive'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 2560, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 73728, 'state': 'active_allocated'},\n",
       "   {'size': 26112, 'state': 'inactive'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 73728, 'state': 'active_allocated'},\n",
       "   {'size': 36864, 'state': 'active_allocated'},\n",
       "   {'size': 16896, 'state': 'inactive'},\n",
       "   {'size': 294912, 'state': 'active_allocated'},\n",
       "   {'size': 73728, 'state': 'active_allocated'},\n",
       "   {'size': 2048, 'state': 'inactive'},\n",
       "   {'size': 110592, 'state': 'active_allocated'},\n",
       "   {'size': 36864, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 1536, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 442368, 'state': 'active_allocated'},\n",
       "   {'size': 73728, 'state': 'active_allocated'},\n",
       "   {'size': 24576, 'state': 'inactive'},\n",
       "   {'size': 1536, 'state': 'active_allocated'},\n",
       "   {'size': 1536, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 36864, 'state': 'active_allocated'},\n",
       "   {'size': 6144, 'state': 'active_allocated'},\n",
       "   {'size': 1536, 'state': 'active_allocated'},\n",
       "   {'size': 1536, 'state': 'active_allocated'},\n",
       "   {'size': 4608, 'state': 'active_allocated'},\n",
       "   {'size': 1536, 'state': 'active_allocated'},\n",
       "   {'size': 1536, 'state': 'active_allocated'},\n",
       "   {'size': 1536, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'}]},\n",
       " {'device': 0,\n",
       "  'address': 140576433373184,\n",
       "  'total_size': 2097152,\n",
       "  'allocated_size': 1587712,\n",
       "  'active_size': 1587712,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'small',\n",
       "  'blocks': [{'size': 108544, 'state': 'inactive'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 36864, 'state': 'active_allocated'},\n",
       "   {'size': 36864, 'state': 'active_allocated'},\n",
       "   {'size': 36864, 'state': 'active_allocated'},\n",
       "   {'size': 6144, 'state': 'active_allocated'},\n",
       "   {'size': 1536, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1536, 'state': 'active_allocated'},\n",
       "   {'size': 1536, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 241664, 'state': 'inactive'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 6144, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 122880, 'state': 'inactive'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1536, 'state': 'active_allocated'},\n",
       "   {'size': 1536, 'state': 'active_allocated'},\n",
       "   {'size': 2560, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 110592, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'state': 'inactive'},\n",
       "   {'size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 36864, 'state': 'active_allocated'},\n",
       "   {'size': 3584, 'state': 'inactive'},\n",
       "   {'size': 27648, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 73728, 'state': 'active_allocated'},\n",
       "   {'size': 8704, 'state': 'inactive'},\n",
       "   {'size': 27648, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 73728, 'state': 'active_allocated'},\n",
       "   {'size': 9216, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'inactive'},\n",
       "   {'size': 18432, 'state': 'active_allocated'},\n",
       "   {'size': 589824, 'state': 'active_allocated'},\n",
       "   {'size': 73728, 'state': 'active_allocated'},\n",
       "   {'size': 20480, 'state': 'inactive'},\n",
       "   {'size': 36864, 'state': 'active_allocated'},\n",
       "   {'size': 36864, 'state': 'active_allocated'},\n",
       "   {'size': 18432, 'state': 'active_allocated'}]},\n",
       " {'device': 0,\n",
       "  'address': 140576963952640,\n",
       "  'total_size': 20971520,\n",
       "  'allocated_size': 6488064,\n",
       "  'active_size': 6488064,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'large',\n",
       "  'blocks': [{'size': 2359296, 'state': 'active_allocated'},\n",
       "   {'size': 2359296, 'state': 'active_allocated'},\n",
       "   {'size': 1769472, 'state': 'active_allocated'},\n",
       "   {'size': 14483456, 'state': 'inactive'}]},\n",
       " {'device': 0,\n",
       "  'address': 140576984924160,\n",
       "  'total_size': 2097152,\n",
       "  'allocated_size': 2081280,\n",
       "  'active_size': 2081280,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'small',\n",
       "  'blocks': [{'size': 589824, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 442368, 'state': 'active_allocated'},\n",
       "   {'size': 589824, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 15872, 'state': 'inactive'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 2560, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'}]},\n",
       " {'device': 0,\n",
       "  'address': 140576987021312,\n",
       "  'total_size': 2097152,\n",
       "  'allocated_size': 2074624,\n",
       "  'active_size': 2074624,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'small',\n",
       "  'blocks': [{'size': 294912, 'state': 'active_allocated'},\n",
       "   {'size': 294912, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 20992, 'state': 'inactive'},\n",
       "   {'size': 2560, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'inactive'},\n",
       "   {'size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1536, 'state': 'active_allocated'},\n",
       "   {'size': 1536, 'state': 'active_allocated'},\n",
       "   {'size': 4608, 'state': 'active_allocated'},\n",
       "   {'size': 1536, 'state': 'active_allocated'},\n",
       "   {'size': 1536, 'state': 'active_allocated'},\n",
       "   {'size': 1536, 'state': 'active_allocated'},\n",
       "   {'size': 1536, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 589824, 'state': 'active_allocated'},\n",
       "   {'size': 589824, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 36864, 'state': 'active_allocated'},\n",
       "   {'size': 73728, 'state': 'active_allocated'},\n",
       "   {'size': 18432, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'inactive'},\n",
       "   {'size': 1536, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'inactive'}]},\n",
       " {'device': 0,\n",
       "  'address': 140577012187136,\n",
       "  'total_size': 2097152,\n",
       "  'allocated_size': 2096128,\n",
       "  'active_size': 2096128,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'small',\n",
       "  'blocks': [{'size': 589824, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 442368, 'state': 'active_allocated'},\n",
       "   {'size': 589824, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 18432, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'inactive'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 2560, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'inactive'},\n",
       "   {'size': 4608, 'state': 'active_allocated'}]},\n",
       " {'device': 0,\n",
       "  'address': 140577848950784,\n",
       "  'total_size': 2097152,\n",
       "  'allocated_size': 2097152,\n",
       "  'active_size': 2097152,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'small',\n",
       "  'blocks': [{'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 294912, 'state': 'active_allocated'},\n",
       "   {'size': 1536, 'state': 'active_allocated'},\n",
       "   {'size': 1024, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 442368, 'state': 'active_allocated'},\n",
       "   {'size': 589824, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 147456, 'state': 'active_allocated'},\n",
       "   {'size': 27648, 'state': 'active_allocated'}]}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_snapshot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_to_allocate  = 5000\n",
    "tensor = torch.zeros((1024**2 * mb_to_allocate // 4,), device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 max memory usage: 119.06 MB\n",
      "2 max memory usage: 2.29 MB\n",
      "4 max memory usage: 2.32 MB\n",
      "8 max memory usage: 2.43 MB\n",
      "16 max memory usage: 2.71 MB\n",
      "32 max memory usage: 3.49 MB\n",
      "64 max memory usage: 5.83 MB\n",
      "128 max memory usage: 13.67 MB\n",
      "256 max memory usage: 42.02 MB\n",
      "512 max memory usage: 149.37 MB\n",
      "1024 max memory usage: 566.56 MB\n",
      "2048 max memory usage: 2210.94 MB\n",
      "4096 max memory usage: 8739.99 MB\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 GiB (GPU 0; 15.74 GiB total capacity; 11.35 GiB already allocated; 1.87 GiB free; 13.10 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m length \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mi\n\u001b[1;32m     14\u001b[0m input_data \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39m1\u001b[39m, length, \u001b[39m64\u001b[39m, device\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcuda:0\u001b[39m\u001b[39m\"\u001b[39m, requires_grad\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 15\u001b[0m output \u001b[39m=\u001b[39m transformer_encoder(input_data)\n\u001b[1;32m     17\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlength\u001b[39m}\u001b[39;00m\u001b[39m max memory usage: \u001b[39m\u001b[39m{\u001b[39;00mtorch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mmax_memory_allocated()\u001b[39m \u001b[39m\u001b[39m/\u001b[39m\u001b[39m \u001b[39m\u001b[39m1024\u001b[39m\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m MB\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mreset_peak_memory_stats()\n",
      "File \u001b[0;32m/data/vision/polina/projects/wmh/dhollidt/conda/envs/nerfstudio2/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/data/vision/polina/projects/wmh/dhollidt/conda/envs/nerfstudio2/lib/python3.8/site-packages/torch/nn/modules/transformer.py:280\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    277\u001b[0m         src_key_padding_mask_for_layers \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[39mfor\u001b[39;00m mod \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m--> 280\u001b[0m     output \u001b[39m=\u001b[39m mod(output, src_mask\u001b[39m=\u001b[39;49mmask, src_key_padding_mask\u001b[39m=\u001b[39;49msrc_key_padding_mask_for_layers)\n\u001b[1;32m    282\u001b[0m \u001b[39mif\u001b[39;00m convert_to_nested:\n\u001b[1;32m    283\u001b[0m     output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mto_padded_tensor(\u001b[39m0.\u001b[39m)\n",
      "File \u001b[0;32m/data/vision/polina/projects/wmh/dhollidt/conda/envs/nerfstudio2/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/data/vision/polina/projects/wmh/dhollidt/conda/envs/nerfstudio2/lib/python3.8/site-packages/torch/nn/modules/transformer.py:538\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    536\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ff_block(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x))\n\u001b[1;32m    537\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 538\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sa_block(x, src_mask, src_key_padding_mask))\n\u001b[1;32m    539\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ff_block(x))\n\u001b[1;32m    541\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/data/vision/polina/projects/wmh/dhollidt/conda/envs/nerfstudio2/lib/python3.8/site-packages/torch/nn/modules/transformer.py:546\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_sa_block\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor,\n\u001b[1;32m    545\u001b[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 546\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attn(x, x, x,\n\u001b[1;32m    547\u001b[0m                        attn_mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[1;32m    548\u001b[0m                        key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask,\n\u001b[1;32m    549\u001b[0m                        need_weights\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    550\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout1(x)\n",
      "File \u001b[0;32m/data/vision/polina/projects/wmh/dhollidt/conda/envs/nerfstudio2/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/data/vision/polina/projects/wmh/dhollidt/conda/envs/nerfstudio2/lib/python3.8/site-packages/torch/nn/modules/activation.py:1167\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights)\u001b[0m\n\u001b[1;32m   1156\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1157\u001b[0m         query, key, value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads,\n\u001b[1;32m   1158\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_weight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1164\u001b[0m         q_proj_weight\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq_proj_weight, k_proj_weight\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk_proj_weight,\n\u001b[1;32m   1165\u001b[0m         v_proj_weight\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv_proj_weight, average_attn_weights\u001b[39m=\u001b[39maverage_attn_weights)\n\u001b[1;32m   1166\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1167\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mmulti_head_attention_forward(\n\u001b[1;32m   1168\u001b[0m         query, key, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_dim, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_heads,\n\u001b[1;32m   1169\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_weight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_bias,\n\u001b[1;32m   1170\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_k, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_v, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_zero_attn,\n\u001b[1;32m   1171\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m   1172\u001b[0m         training\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining,\n\u001b[1;32m   1173\u001b[0m         key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask, need_weights\u001b[39m=\u001b[39;49mneed_weights,\n\u001b[1;32m   1174\u001b[0m         attn_mask\u001b[39m=\u001b[39;49mattn_mask, average_attn_weights\u001b[39m=\u001b[39;49maverage_attn_weights)\n\u001b[1;32m   1175\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first \u001b[39mand\u001b[39;00m is_batched:\n\u001b[1;32m   1176\u001b[0m     \u001b[39mreturn\u001b[39;00m attn_output\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m/data/vision/polina/projects/wmh/dhollidt/conda/envs/nerfstudio2/lib/python3.8/site-packages/torch/nn/functional.py:5162\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights)\u001b[0m\n\u001b[1;32m   5160\u001b[0m     attn_output_weights \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mbaddbmm(attn_mask, q_scaled, k\u001b[39m.\u001b[39mtranspose(\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[1;32m   5161\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 5162\u001b[0m     attn_output_weights \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mbmm(q_scaled, k\u001b[39m.\u001b[39;49mtranspose(\u001b[39m-\u001b[39;49m\u001b[39m2\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m))\n\u001b[1;32m   5163\u001b[0m attn_output_weights \u001b[39m=\u001b[39m softmax(attn_output_weights, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m   5164\u001b[0m \u001b[39mif\u001b[39;00m dropout_p \u001b[39m>\u001b[39m \u001b[39m0.0\u001b[39m:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 GiB (GPU 0; 15.74 GiB total capacity; 11.35 GiB already allocated; 1.87 GiB free; 13.10 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "encoder_layer = torch.nn.TransformerEncoderLayer(\n",
    "            64,\n",
    "            8,\n",
    "            64,\n",
    "            0.2,\n",
    "            batch_first=True,\n",
    "        )\n",
    "transformer_encoder = torch.nn.TransformerEncoder(encoder_layer, 6)\n",
    "transformer_encoder.to(\"cuda:0\")\n",
    "\n",
    "for i in range(16):\n",
    "    length = 2**i\n",
    "    input_data = torch.randn(1, length, 64, device=\"cuda:0\", requires_grad=True)\n",
    "    output = transformer_encoder(input_data)\n",
    "\n",
    "    print(f\"{length} max memory usage: {torch.cuda.max_memory_allocated() / 1024**2:.2f} MB\")\n",
    "    torch.cuda.reset_peak_memory_stats()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerfstudio3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d982505c67f6491cc57124614a47f97cb6b2fba9cbe418d2edc6b5ed45f83d2f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
