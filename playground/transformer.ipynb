{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(torch.nn.Module):\n",
    "    def __init__(self, output_size, num_layers, d_model, num_heads, dff, dropout_rate):\n",
    "        super().__init__()\n",
    "\n",
    "        # Define the transformer encoder\n",
    "        self.encoder_layer = torch.nn.TransformerEncoderLayer(d_model, num_heads, dff, dropout_rate, batch_first=True)\n",
    "        self.transformer_encoder = torch.nn.TransformerEncoder(self.encoder_layer, num_layers)\n",
    "\n",
    "        # Define the output layer\n",
    "        self.final_layer = torch.nn.Linear(d_model, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply the transformer encoder\n",
    "        x = self.transformer_encoder(x)\n",
    "\n",
    "        # Apply the final layer\n",
    "        x = self.final_layer(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250182\n",
      "torch.Size([1, 8, 128])\n",
      "torch.Size([1, 8, 6])\n"
     ]
    }
   ],
   "source": [
    "# Define the input and output sizes\n",
    "input_size = 8\n",
    "output_size = 6\n",
    "\n",
    "# Define the transformer model\n",
    "num_layers = 2\n",
    "d_model = 128\n",
    "num_heads = 4\n",
    "dff = 64\n",
    "dropout_rate = 0.1\n",
    "model = TransformerModel(output_size, num_layers, d_model, num_heads, dff, dropout_rate)\n",
    "\n",
    "# Generate some example input data\n",
    "batch_size = 1\n",
    "seq_length = input_size\n",
    "input_data = torch.randn(batch_size, seq_length, d_model)\n",
    "\n",
    "# print the parameters of the model\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(total_params)\n",
    "\n",
    "# Pass the input data through the model to get the output\n",
    "print(input_data.shape)\n",
    "output_data = model(input_data)\n",
    "# expect 16, 10, 6\n",
    "print(output_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "TransformerModel                              [1, 16000, 6]             83,136\n",
       "├─TransformerEncoder: 1-1                     [1, 16000, 128]           --\n",
       "│    └─ModuleList: 2-1                        --                        --\n",
       "│    │    └─TransformerEncoderLayer: 3-1      [1, 16000, 128]           83,136\n",
       "│    │    └─TransformerEncoderLayer: 3-2      [1, 16000, 128]           83,136\n",
       "├─Linear: 1-2                                 [1, 16000, 6]             774\n",
       "===============================================================================================\n",
       "Total params: 250,182\n",
       "Trainable params: 250,182\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.00\n",
       "===============================================================================================\n",
       "Input size (MB): 8.19\n",
       "Forward/backward pass size (MB): 0.77\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 8.96\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "seq_length = 16000\n",
    "summary(model, input_size=(batch_size, seq_length, d_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
    "transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=6)\n",
    "src = torch.rand(10, 32, 512)\n",
    "out = transformer_encoder(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 32, 512])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 32, 512])\n",
      "tensor([[[0.8831, 0.7192, 0.7406,  ..., 0.8938, 0.6347, 0.5211],\n",
      "         [0.2122, 0.4283, 0.1966,  ..., 0.2230, 0.0964, 0.0918],\n",
      "         [0.7867, 0.8161, 0.5503,  ..., 0.8816, 0.2052, 0.5661],\n",
      "         ...,\n",
      "         [0.4690, 0.1957, 0.8169,  ..., 0.3704, 0.0157, 0.3309],\n",
      "         [0.3612, 0.8310, 0.9841,  ..., 0.4858, 0.4641, 0.8028],\n",
      "         [0.0825, 0.4360, 0.0565,  ..., 0.1524, 0.3171, 0.8398]],\n",
      "\n",
      "        [[0.4719, 0.3796, 0.5296,  ..., 0.8090, 0.1761, 0.2643],\n",
      "         [0.0157, 0.2695, 0.6866,  ..., 0.6252, 0.8721, 0.7033],\n",
      "         [0.2062, 0.2626, 0.8744,  ..., 0.4858, 0.9292, 0.9802],\n",
      "         ...,\n",
      "         [0.1701, 0.1103, 0.1372,  ..., 0.7573, 0.0362, 0.4542],\n",
      "         [0.7662, 0.3510, 0.6453,  ..., 0.9619, 0.7399, 0.8724],\n",
      "         [0.3191, 0.2178, 0.6184,  ..., 0.6606, 0.6076, 0.3059]],\n",
      "\n",
      "        [[0.7307, 0.7800, 0.7666,  ..., 0.7604, 0.5445, 0.5923],\n",
      "         [0.7473, 0.8057, 0.5010,  ..., 0.7684, 0.9257, 0.0859],\n",
      "         [0.9730, 0.5786, 0.2559,  ..., 0.9745, 0.0030, 0.4733],\n",
      "         ...,\n",
      "         [0.4746, 0.5789, 0.8716,  ..., 0.2628, 0.1958, 0.4416],\n",
      "         [0.7325, 0.6984, 0.7170,  ..., 0.5765, 0.9003, 0.7987],\n",
      "         [0.2070, 0.3274, 0.0626,  ..., 0.6010, 0.3080, 0.2562]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.8402, 0.6093, 0.5041,  ..., 0.4715, 0.9849, 0.1654],\n",
      "         [0.2414, 0.0331, 0.2373,  ..., 0.0849, 0.8827, 0.7494],\n",
      "         [0.8596, 0.8501, 0.4687,  ..., 0.2218, 0.7886, 0.1047],\n",
      "         ...,\n",
      "         [0.8071, 0.7259, 0.5345,  ..., 0.7954, 0.1646, 0.5804],\n",
      "         [0.5150, 0.4425, 0.2821,  ..., 0.2428, 0.4609, 0.8516],\n",
      "         [0.8153, 0.5537, 0.7411,  ..., 0.7397, 0.9300, 0.4925]],\n",
      "\n",
      "        [[0.6043, 0.2235, 0.4951,  ..., 0.8776, 0.9816, 0.7597],\n",
      "         [0.6402, 0.9666, 0.0659,  ..., 0.3715, 0.8840, 0.8624],\n",
      "         [0.5050, 0.6450, 0.1254,  ..., 0.4845, 0.8447, 0.2562],\n",
      "         ...,\n",
      "         [0.7338, 0.2147, 0.2836,  ..., 0.7848, 0.1017, 0.4751],\n",
      "         [0.4700, 0.9877, 0.1918,  ..., 0.1446, 0.4324, 0.2653],\n",
      "         [0.5109, 0.2694, 0.0376,  ..., 0.8411, 0.0447, 0.2143]],\n",
      "\n",
      "        [[0.8009, 0.2093, 0.8261,  ..., 0.5041, 0.7182, 0.7480],\n",
      "         [0.3643, 0.1058, 0.3999,  ..., 0.0689, 0.5644, 0.4814],\n",
      "         [0.0850, 0.7235, 0.1892,  ..., 0.2571, 0.3210, 0.2737],\n",
      "         ...,\n",
      "         [0.1516, 0.2648, 0.2774,  ..., 0.9806, 0.7085, 0.1631],\n",
      "         [0.1934, 0.4440, 0.4751,  ..., 0.9542, 0.8035, 0.2331],\n",
      "         [0.7790, 0.1419, 0.1260,  ..., 0.4062, 0.3704, 0.1368]]])\n",
      "tensor([[[ 2.5746e+00, -8.0230e-01,  2.0076e+00,  ..., -2.2814e-01,\n",
      "           2.8878e-01, -6.0285e-01],\n",
      "         [ 1.4478e+00, -7.8584e-02,  1.6759e+00,  ..., -2.4033e-02,\n",
      "           2.3275e-01, -2.2146e+00],\n",
      "         [ 2.4374e+00, -8.8890e-01,  1.1874e+00,  ..., -6.7550e-01,\n",
      "          -5.0762e-01, -9.6921e-01],\n",
      "         ...,\n",
      "         [ 1.6500e+00, -4.8093e-01,  2.2919e+00,  ..., -3.3334e-01,\n",
      "           7.1427e-01, -1.1015e+00],\n",
      "         [ 1.7793e+00,  1.0455e-01,  2.6299e+00,  ...,  4.1233e-01,\n",
      "          -1.0750e-01, -1.5533e+00],\n",
      "         [ 2.8255e+00, -1.3363e+00,  1.8914e+00,  ..., -7.4848e-03,\n",
      "           7.8254e-01, -1.1788e+00]],\n",
      "\n",
      "        [[ 2.6849e+00, -1.1922e+00,  1.6256e+00,  ..., -5.4887e-01,\n",
      "          -2.8006e-01, -1.7983e+00],\n",
      "         [ 1.5183e+00,  2.6389e-01,  2.0236e+00,  ...,  7.9062e-01,\n",
      "           1.7009e-02, -1.9149e+00],\n",
      "         [ 2.0357e+00, -1.7843e+00,  1.3524e+00,  ..., -8.8080e-01,\n",
      "          -5.7793e-01, -5.4684e-01],\n",
      "         ...,\n",
      "         [ 2.3586e+00, -5.6607e-01,  1.4165e+00,  ..., -1.2408e+00,\n",
      "           2.1409e-01, -1.1583e+00],\n",
      "         [ 2.0614e+00, -5.1045e-01,  1.0964e+00,  ..., -4.4011e-01,\n",
      "          -3.5406e-01, -1.3765e+00],\n",
      "         [ 1.9775e+00, -5.5462e-01,  1.7686e+00,  ..., -2.1881e-01,\n",
      "           4.6642e-01, -1.1361e+00]],\n",
      "\n",
      "        [[ 2.7407e+00, -8.7334e-01,  1.3197e+00,  ..., -4.2676e-01,\n",
      "          -4.0815e-01, -2.0905e+00],\n",
      "         [ 1.2528e+00, -2.2261e-01,  1.5048e+00,  ...,  3.3825e-01,\n",
      "           2.3263e-01, -1.8475e+00],\n",
      "         [ 2.3730e+00, -1.5005e+00,  2.1592e+00,  ...,  3.8029e-01,\n",
      "          -2.7655e-01, -7.2319e-01],\n",
      "         ...,\n",
      "         [ 1.3735e+00, -7.3751e-01,  1.4160e+00,  ..., -1.9409e+00,\n",
      "           7.8733e-03, -1.8905e+00],\n",
      "         [ 1.5037e+00,  1.5400e-01,  1.4269e+00,  ...,  9.7967e-02,\n",
      "           5.2790e-01, -1.1756e+00],\n",
      "         [ 2.2812e+00, -2.5113e-01,  1.7431e+00,  ..., -4.4820e-01,\n",
      "          -6.0089e-01, -1.3859e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.4566e+00, -9.6611e-01,  2.5160e+00,  ..., -1.8848e-01,\n",
      "           4.5240e-01, -5.8747e-01],\n",
      "         [ 6.9127e-01, -8.0562e-02,  1.6816e+00,  ...,  5.3182e-01,\n",
      "           1.5737e-01, -1.6311e+00],\n",
      "         [ 2.9123e+00, -7.9887e-01,  1.5643e+00,  ...,  2.9464e-01,\n",
      "          -5.5512e-01, -7.7312e-01],\n",
      "         ...,\n",
      "         [ 2.5482e+00, -4.5581e-01,  1.5588e+00,  ..., -6.5107e-01,\n",
      "           6.9382e-01, -6.1376e-01],\n",
      "         [ 2.6270e+00, -5.1537e-01,  2.1710e+00,  ..., -3.0960e-01,\n",
      "          -5.6613e-01, -1.3642e+00],\n",
      "         [ 1.4768e+00, -1.1856e+00,  2.1027e+00,  ..., -2.9713e-03,\n",
      "           1.1058e-02, -2.2233e-01]],\n",
      "\n",
      "        [[ 2.8159e+00, -1.0875e+00,  1.8576e+00,  ..., -7.0021e-01,\n",
      "           6.1266e-01, -2.0924e-01],\n",
      "         [ 4.6857e-01, -5.3402e-01,  1.8084e+00,  ..., -1.0627e-01,\n",
      "           3.0961e-01, -1.1643e+00],\n",
      "         [ 2.2224e+00, -1.3637e+00,  1.7314e+00,  ...,  1.4527e-01,\n",
      "          -8.2232e-01, -9.3835e-01],\n",
      "         ...,\n",
      "         [ 2.1674e+00, -9.7223e-01,  8.9994e-01,  ..., -1.4217e+00,\n",
      "           1.6278e-01, -1.4502e+00],\n",
      "         [ 1.6589e+00,  2.7809e-01,  1.4853e+00,  ..., -6.5734e-01,\n",
      "           4.0079e-01, -9.6012e-02],\n",
      "         [ 3.1187e+00, -7.3649e-01,  2.4654e+00,  ..., -8.3369e-01,\n",
      "          -5.8940e-01, -9.2816e-01]],\n",
      "\n",
      "        [[ 2.2705e+00, -4.3950e-01,  2.7269e+00,  ..., -3.3335e-01,\n",
      "           9.1416e-02, -9.4678e-01],\n",
      "         [ 1.1487e+00, -2.1898e-01,  1.4759e+00,  ..., -3.1562e-01,\n",
      "           6.0291e-01, -6.8027e-01],\n",
      "         [ 1.9353e+00, -1.0521e+00,  1.4139e+00,  ..., -1.6311e-01,\n",
      "          -1.3940e+00, -2.0977e+00],\n",
      "         ...,\n",
      "         [ 7.0817e-01,  2.1777e-01,  1.1347e+00,  ..., -2.0312e-01,\n",
      "          -1.1823e-01, -1.8717e+00],\n",
      "         [ 7.3809e-01, -1.0444e-01,  1.5679e+00,  ...,  1.3519e-02,\n",
      "           6.7285e-01, -1.5204e+00],\n",
      "         [ 2.1103e+00,  1.3498e-01,  1.9555e+00,  ..., -5.3918e-01,\n",
      "           2.8270e-01, -6.9256e-01]]], grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "transformer_model = nn.Transformer(nhead=16, num_encoder_layers=12)\n",
    "src = torch.rand((10, 32, 512))\n",
    "tgt = torch.rand((20, 32, 512))\n",
    "out = transformer_model(src, tgt)\n",
    "print(out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerfstudio3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d982505c67f6491cc57124614a47f97cb6b2fba9cbe418d2edc6b5ed45f83d2f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
